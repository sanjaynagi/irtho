{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccc94c1-852a-4985-865f-b5403cce10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e5bea1-dfbd-405f-9ad7-7eaaaf7396dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "def load_fasta(fasta_path, debug=False):\n",
    "    \"\"\"\n",
    "    Load sequences from a FASTA file into a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        fasta_path: Path to the FASTA file.\n",
    "        debug: Whether to print debug information.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary of sequences keyed by protein ID.\n",
    "    \"\"\"\n",
    "    sequences = {}\n",
    "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
    "        sequences[record.id] = str(record.seq)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Loaded {len(sequences)} sequences from {fasta_path}\")\n",
    "        print(f\"Sample IDs: {list(sequences.keys())[:3]}\")\n",
    "        print(f\"Length range: {min(len(seq) for seq in sequences.values())} - {max(len(seq) for seq in sequences.values())}\")\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def create_gene_mapping(file_path):\n",
    "    \"\"\"\n",
    "    Parse a GFF file and create a mapping from genes to transcripts to proteins.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the GFF file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns ['gene_id', 'transcript_id', 'protein_id'].\n",
    "    \"\"\"\n",
    "    mappings = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        gene_id = None\n",
    "        transcript_id = None\n",
    "\n",
    "        for line in file:\n",
    "            # Skip comments and empty lines\n",
    "            if line.startswith(\"#\") or not line.strip():\n",
    "                continue\n",
    "\n",
    "            # Split the line into columns\n",
    "            columns = line.strip().split(\"\\t\")\n",
    "            if len(columns) < 9:\n",
    "                continue  # Skip malformed lines\n",
    "\n",
    "            feature_type = columns[2]  # The third column indicates the feature type\n",
    "            attributes = columns[8]  # The ninth column contains the attributes\n",
    "\n",
    "            # Parse the attributes into a dictionary\n",
    "            attr_dict = {}\n",
    "            for attr in attributes.split(\";\"):\n",
    "                if \"=\" in attr:\n",
    "                    key, value = attr.split(\"=\", 1)\n",
    "                    attr_dict[key.strip()] = value.strip()\n",
    "\n",
    "            # Extract gene_id and transcript_id from mRNA or transcript rows\n",
    "            if feature_type in {\"mRNA\", \"transcript\"}:\n",
    "                transcript_id = attr_dict.get(\"ID\")\n",
    "                gene_id = attr_dict.get(\"Parent\")\n",
    "\n",
    "            # Extract protein_id from CDS rows\n",
    "            elif feature_type == \"CDS\":\n",
    "                protein_id = attr_dict.get(\"protein_source_id\") or attr_dict.get(\"protein_id\")\n",
    "                if gene_id and transcript_id and protein_id:\n",
    "                    mappings.append((gene_id, transcript_id, protein_id))\n",
    "\n",
    "    # Create a DataFrame from the mappings\n",
    "    df = pd.DataFrame(mappings, columns=[\"gene_id\", \"transcript_id\", \"protein_id\"])\n",
    "    df.loc[:, 'gene_id'] = df.gene_id.str.replace(\"gene-\", \"\")\n",
    "    df.loc[:, 'transcript_id'] = df.transcript_id.str.replace(\"rna-\", \"\")\n",
    "    return df.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "def get_longest_transcripts(sequences, mapping_df, debug=False):\n",
    "    \"\"\"\n",
    "    Find the longest transcript for each gene using the mapping DataFrame.\n",
    "\n",
    "    Args:\n",
    "        sequences: Dictionary of protein sequences keyed by protein ID.\n",
    "        mapping_df: DataFrame with columns ['gene_id', 'transcript_id', 'protein_id'].\n",
    "        debug: Whether to print debug information.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of longest transcripts keyed by gene ID.\n",
    "    \"\"\"\n",
    "    # Filter the mapping DataFrame to include only rows where the protein_id exists in the sequences\n",
    "    mapping_df = mapping_df[mapping_df[\"protein_id\"].isin(sequences.keys())]\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Filtered mapping file to {len(mapping_df)} rows with valid protein IDs.\")\n",
    "        print(f\"Sample mapping rows:\\n{mapping_df.head()}\")\n",
    "\n",
    "    # Group transcripts by gene ID\n",
    "    gene_transcripts = mapping_df.groupby(\"gene_id\").apply(\n",
    "        lambda group: group[[\"transcript_id\", \"protein_id\"]].to_dict(orient=\"records\")\n",
    "    ).to_dict()\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Found {len(gene_transcripts)} unique genes in the mapping file.\")\n",
    "        print(f\"Sample gene-transcript mappings: {list(gene_transcripts.items())[:3]}\")\n",
    "\n",
    "    # Keep the longest transcript for each gene\n",
    "    longest_transcripts = {}\n",
    "    for gene_id, transcript_records in gene_transcripts.items():\n",
    "        # Map protein IDs to sequences and find the longest\n",
    "        valid_transcripts = [\n",
    "            (record[\"transcript_id\"], record[\"protein_id\"], sequences[record[\"protein_id\"]])\n",
    "            for record in transcript_records\n",
    "            if record[\"protein_id\"] in sequences\n",
    "        ]\n",
    "\n",
    "        if not valid_transcripts:\n",
    "            if debug:\n",
    "                print(f\"Warning: No valid transcripts found for gene {gene_id}\")\n",
    "            continue\n",
    "\n",
    "        # Find the longest transcript\n",
    "        longest = max(valid_transcripts, key=lambda x: len(x[2]))\n",
    "        longest_transcripts[gene_id] = (longest[0], longest[2])  # (transcript_id, sequence)\n",
    "\n",
    "        if debug and len(valid_transcripts) > 1:\n",
    "            lengths = [(t[0], len(t[2])) for t in valid_transcripts]\n",
    "            print(f\"\\nGene {gene_id} transcripts:\")\n",
    "            for tid, length in lengths:\n",
    "                print(f\"  {tid}: {length} aa{'*' if tid == longest[0] else ''}\")\n",
    "\n",
    "    return longest_transcripts\n",
    "\n",
    "def write_fasta(sequences, output_path, debug=False):\n",
    "    \"\"\"\n",
    "    Write sequences to a FASTA file with line wrapping at 60 characters.\n",
    "\n",
    "    Args:\n",
    "        sequences: Dictionary of sequences keyed by gene ID.\n",
    "        output_path: Path to the output FASTA file.\n",
    "        debug: Whether to print debug information.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        for gene_id, (transcript_id, sequence) in sequences.items():\n",
    "            f.write(f\">{transcript_id}\\n\")\n",
    "            for i in range(0, len(sequence), 60):\n",
    "                f.write(f\"{sequence[i:i+60]}\\n\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Wrote {len(sequences)} sequences to {output_path}\")\n",
    "        print(f\"Total residues written: {sum(len(seq[1]) for seq in sequences.values())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90fcdb-91a4-4eb7-9593-93286e687db2",
   "metadata": {},
   "source": [
    "### what we need\n",
    "\n",
    "Protein fasta, DNA fasta, GFF. Beginning with two references, one input, one output.\n",
    "\n",
    "1. Load protein fasta + gff and find longest transcripts\n",
    "2. Subset to only longest transcripts\n",
    "3. Run Orthofinder\n",
    "4. Find main orthologs, calculate synteny, find syntenic orthologs\n",
    "5. Visualise synteny / Orthology in each species\n",
    "6. Once we have genes, take each gene and each snp, align them, find the new position in the new reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e674bb-3edc-4631-94e0-b84846b55dd3",
   "metadata": {},
   "source": [
    "Lets locate our reference genomes in the `resources/reference` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc42eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AaegyptiLVP_AGWG', 'Aalbopictus_AalbF5', 'AdirusWRAIR2',\n",
       "       'AfunestusAfunGA1', 'AgambiaePEST', 'AminimusMINIMUS1',\n",
       "       'AsinensisChina', 'AstephensiUCISS2018',\n",
       "       'CquinquefasciatusJHB2020', 'LlongipalpisASM'], dtype='<U24')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "vb_refs = [ref.split(\"reference/\")[1].rstrip(\".gff\") for ref in glob.glob('../resources/reference/*gff')]\n",
    "np.sort(vb_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ba642-34da-4be0-a5a9-623fb8bcd4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de779997-0a6a-43db-b3d4-69dcbaf2b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15328 sequences from ../resources/reference/AgambiaePEST_AnnotatedProteins.fasta\n",
      "Sample IDs: ['AGAP004677.P162', 'AGAP004677.P163', 'AGAP004678-PA']\n",
      "Length range: 16 - 16221\n",
      "Wrote 13107 sequences to ../results/proteome/AgambiaePEST.fasta\n",
      "Total residues written: 7401200\n",
      "\n",
      "\n",
      "Loaded 24676 sequences from ../resources/reference/CquinquefasciatusJHB2020_AnnotatedProteins.fasta\n",
      "Sample IDs: ['CQUJHB000005.P10', 'CQUJHB000005.P11', 'CQUJHB000005.P12']\n",
      "Length range: 36 - 18876\n",
      "Wrote 15276 sequences to ../results/proteome/CquinquefasciatusJHB2020.fasta\n",
      "Total residues written: 8390556\n",
      "\n",
      "\n",
      "Loaded 20287 sequences from ../resources/reference/LlongipalpisASM_AnnotatedProteins.fasta\n",
      "Sample IDs: ['XP_055676422.1', 'XP_055676423.1', 'XP_055676424.1']\n",
      "Length range: 28 - 22183\n",
      "Wrote 11238 sequences to ../results/proteome/LlongipalpisASM.fasta\n",
      "Total residues written: 6570367\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# genomes = np.array([\n",
    "#        'AaegyptiLVP_AGWG', 'Aalbopictus_AalbF5', 'AdirusWRAIR2',\n",
    "#        'AfunestusAfunGA1', 'AgambiaePEST', 'AminimusMINIMUS1',\n",
    "#        'AsinensisChina', 'AstephensiUCISS2018',\n",
    "#        'CquinquefasciatusJHB2020', 'LlongipalpisASM']\n",
    "# )\n",
    "\n",
    "genomes = ['AgambiaePEST', 'CquinquefasciatusJHB2020', 'LlongipalpisASM']\n",
    "\n",
    "for g in genomes:\n",
    "    sequences = load_fasta(f\"../resources/reference/{g}_AnnotatedProteins.fasta\", debug=True)\n",
    "    df_mapping = create_gene_mapping(f\"../resources/reference/{g}.gff\")\n",
    "    longest_transcripts = get_longest_transcripts(sequences, df_mapping, debug=False)\n",
    "    write_fasta(longest_transcripts, f\"../results/proteome/{g}.fasta\", debug=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f90eb9-2d25-47a1-b9ae-d7125fd1856c",
   "metadata": {},
   "source": [
    "## Run Orthofinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2416cb0",
   "metadata": {},
   "source": [
    "### Synteny analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "010f29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_orthofinder(input_dir, pixi_env=\"pixi\", additional_args=None, debug=False):\n",
    "    \"\"\"\n",
    "    Run OrthoFinder on a given directory using pixi for environment setup.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing input files for OrthoFinder.\n",
    "        pixi_env (str): The pixi environment command (default is 'pixi').\n",
    "        additional_args (list): Additional arguments to pass to the OrthoFinder command.\n",
    "        debug (bool): Whether to print debug information.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure additional_args is a list\n",
    "    if additional_args is None:\n",
    "        additional_args = []\n",
    "\n",
    "    # Construct the OrthoFinder command\n",
    "    command = [pixi_env, \"run\", \"orthofinder\", \"-f\", input_dir] + additional_args\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Running OrthoFinder with the following command:\")\n",
    "        print(\" \".join(command))\n",
    "        print(f\"Input directory: {input_dir}\")\n",
    "        if additional_args:\n",
    "            print(f\"Additional arguments: {additional_args}\")\n",
    "\n",
    "    try:\n",
    "        # Run the command and capture the output\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        # Stream the output to the console\n",
    "        for line in process.stdout:\n",
    "            print(line, end=\"\")  # Print each line as it is received\n",
    "\n",
    "        # Wait for the process to complete and capture the return code\n",
    "        process.wait()\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            # If the process failed, print the error output\n",
    "            error_output = process.stderr.read()\n",
    "            print(f\"\\nError: OrthoFinder failed with return code {process.returncode}\")\n",
    "            print(f\"Error details:\\n{error_output}\")\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"\\nOrthoFinder completed successfully.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: The command '{command[0]}' was not found. Is pixi installed and in your PATH?\")\n",
    "        if debug:\n",
    "            print(f\"Details: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while running OrthoFinder.\")\n",
    "        if debug:\n",
    "            print(f\"Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67fe317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running OrthoFinder with the following command:\n",
      "pixi run orthofinder -f ../results/proteome/ -t 4 -o ../results/orthofinder\n",
      "Input directory: ../results/proteome/\n",
      "Additional arguments: ['-t', '4', '-o', '../results/orthofinder']\n",
      "\n",
      "OrthoFinder version 2.5.5 Copyright (C) 2014 David Emms\n",
      "\n",
      "2025-01-29 10:24:57 : Starting OrthoFinder 2.5.5\n",
      "4 thread(s) for highly parallel tasks (BLAST searches etc.)\n",
      "1 thread(s) for OrthoFinder algorithm\n",
      "\n",
      "Checking required programs are installed\n",
      "----------------------------------------\n",
      "Test can run \"mcl -h\" - ok\n",
      "Test can run \"fastme -i ../results/orthofinder/Results_Jan29/WorkingDirectory/dependencies/SimpleTest.phy -o ../results/orthofinder/Results_Jan29/WorkingDirectory/dependencies/SimpleTest.tre\" - ok\n",
      "\n",
      "Dividing up work for BLAST for parallel processing\n",
      "--------------------------------------------------\n",
      "2025-01-29 10:24:58 : Creating diamond database 1 of 3\n",
      "2025-01-29 10:24:58 : Creating diamond database 2 of 3\n",
      "2025-01-29 10:24:58 : Creating diamond database 3 of 3\n",
      "\n",
      "Running diamond all-versus-all\n",
      "------------------------------\n",
      "Using 4 thread(s)\n",
      "2025-01-29 10:24:58 : This may take some time....\n",
      "2025-01-29 10:24:58 : Done 0 of 9\n",
      "2025-01-29 10:44:26 : Done all-versus-all sequence search\n",
      "\n",
      "Running OrthoFinder algorithm\n",
      "-----------------------------\n",
      "2025-01-29 10:44:26 : Initial processing of each species\n",
      "2025-01-29 10:44:36 : Initial processing of species 0 complete\n",
      "2025-01-29 10:44:41 : Initial processing of species 1 complete\n",
      "2025-01-29 10:44:48 : Initial processing of species 2 complete\n",
      "2025-01-29 10:44:52 : Connected putative homologues\n",
      "2025-01-29 10:44:54 : Written final scores for species 0 to graph file\n",
      "2025-01-29 10:44:54 : Written final scores for species 1 to graph file\n",
      "2025-01-29 10:44:56 : Written final scores for species 2 to graph file\n",
      "2025-01-29 10:45:03 : Ran MCL\n",
      "\n",
      "Writing orthogroups to file\n",
      "---------------------------\n",
      "OrthoFinder assigned 46271 genes (94.8% of total) to 12431 orthogroups. Fifty percent of all genes were in orthogroups with 3 or more genes (G50 was 3) and were contained in the largest 4559 orthogroups (O50 was 4559). There were 9085 orthogroups with all species present and 7059 of these consisted entirely of single-copy genes.\n",
      "\n",
      "2025-01-29 10:45:07 : Done orthogroups\n",
      "\n",
      "Analysing Orthogroups\n",
      "=====================\n",
      "\n",
      "Calculating gene distances\n",
      "--------------------------\n",
      "2025-01-29 10:45:32 : Done\n",
      "2025-01-29 10:45:32 : Done 0 of 3104\n",
      "2025-01-29 10:45:34 : Done 1000 of 3104\n",
      "2025-01-29 10:45:35 : Done 2000 of 3104\n",
      "2025-01-29 10:45:36 : Done 3000 of 3104\n",
      "\n",
      "Inferring gene and species trees\n",
      "--------------------------------\n",
      "\n",
      "Best outgroup(s) for species tree\n",
      "---------------------------------\n",
      "2025-01-29 10:45:37 : Starting STRIDE\n",
      "2025-01-29 10:45:38 : Done STRIDE\n",
      "Observed 66 well-supported, non-terminal duplications. 54 support the best root and 12 contradict it.\n",
      "Best outgroup for species tree:\n",
      "  AgambiaePEST-proteins\n",
      "\n",
      "Reconciling gene trees and species tree\n",
      "---------------------------------------\n",
      "Outgroup: AgambiaePEST-proteins\n",
      "2025-01-29 10:45:38 : Starting Recon and orthologues\n",
      "2025-01-29 10:45:38 : Starting OF Orthologues\n",
      "2025-01-29 10:45:38 : Done 0 of 3104\n",
      "2025-01-29 10:45:42 : Done 1000 of 3104\n",
      "2025-01-29 10:45:45 : Done 2000 of 3104\n",
      "2025-01-29 10:45:48 : Done 3000 of 3104\n",
      "2025-01-29 10:45:49 : Done OF Orthologues\n",
      "\n",
      "Writing results files\n",
      "=====================\n",
      "2025-01-29 10:45:52 : Done orthologues\n",
      "\n",
      "Results:\n",
      "    ../results/orthofinder/Results_Jan29/\n",
      "\n",
      "CITATION:\n",
      " When publishing work that uses OrthoFinder please cite:\n",
      " Emms D.M. & Kelly S. (2019), Genome Biology 20:238\n",
      "\n",
      " If you use the species tree in your work then please also cite:\n",
      " Emms D.M. & Kelly S. (2017), MBE 34(12): 3267-3278\n",
      " Emms D.M. & Kelly S. (2018), bioRxiv https://doi.org/10.1101/267914\n",
      "\n",
      "OrthoFinder completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Run OrthoFinder on a directory with additional arguments\n",
    "input_directory = \"../results/proteome/\"\n",
    "additional_arguments = [\"-t\", \"4\", \"-o\", \"../results/orthofinder\"]  # Example: Use 4 threads\n",
    "run_orthofinder(input_directory, additional_args=additional_arguments, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a48bae-d4bc-44f4-a2c7-f3288025cf6b",
   "metadata": {},
   "source": [
    "### Orthofinder results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4878cb29-c51c-4d3a-8f73-536f32280d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class OrthoFinderResults:\n",
    "    \"\"\"\n",
    "    A class to parse and store relevant information from OrthoFinder output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, results_dir, debug=False):\n",
    "        \"\"\"\n",
    "        Initialize the OrthoFinderResults class.\n",
    "\n",
    "        Args:\n",
    "            results_dir (str): Path to the OrthoFinder results directory.\n",
    "            debug (bool): Whether to print debug information.\n",
    "        \"\"\"\n",
    "        self.results_dir = results_dir\n",
    "        self.debug = debug\n",
    "        self.orthologues_stats = None\n",
    "        self.hierarchical_orthogroups = None\n",
    "        self.one_to_one_orthologs = None\n",
    "\n",
    "        if debug:\n",
    "            print(f\"Initializing OrthoFinderResults for directory: {results_dir}\")\n",
    "\n",
    "        # Load relevant files\n",
    "        self._load_orthologues_stats()\n",
    "        self._load_hierarchical_orthogroups()\n",
    "\n",
    "    def _load_orthologues_stats(self):\n",
    "        \"\"\"\n",
    "        Load the one-to-one orthologs statistics file.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(\n",
    "            self.results_dir, \"Comparative_Genomics_Statistics\", \"OrthologuesStats_one-to-one.tsv\"\n",
    "        )\n",
    "        if os.path.exists(file_path):\n",
    "            if self.debug:\n",
    "                print(f\"Loading one-to-one orthologs from: {file_path}\")\n",
    "            self.orthologues_stats = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "        else:\n",
    "            if self.debug:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "            self.orthologues_stats = None\n",
    "\n",
    "    def _load_hierarchical_orthogroups(self):\n",
    "        \"\"\"\n",
    "        Load the hierarchical orthogroups file (N0.tsv).\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(\n",
    "            self.results_dir, \"Phylogenetic_Hierarchical_Orthogroups\", \"N0.tsv\"\n",
    "        )\n",
    "        if os.path.exists(file_path):\n",
    "            if self.debug:\n",
    "                print(f\"Loading hierarchical orthogroups from: {file_path}\")\n",
    "            self.hierarchical_orthogroups = pd.read_csv(file_path, sep=\"\\t\")\n",
    "        else:\n",
    "            if self.debug:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "            self.hierarchical_orthogroups = None\n",
    "\n",
    "    def get_one_to_one_orthologs(self, species_a, species_b):\n",
    "        \"\"\"\n",
    "        Get one-to-one orthologs between two species.\n",
    "\n",
    "        Args:\n",
    "            species_a (str): Name of the first species.\n",
    "            species_b (str): Name of the second species.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing one-to-one orthologs between the two species.\n",
    "        \"\"\"\n",
    "        if self.orthologues_stats is None:\n",
    "            raise ValueError(\"One-to-one orthologs statistics file not loaded.\")\n",
    "\n",
    "        if species_a not in self.orthologues_stats.columns or species_b not in self.orthologues_stats.columns:\n",
    "            raise ValueError(f\"Species {species_a} or {species_b} not found in the orthologs statistics.\")\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Retrieving one-to-one orthologs between {species_a} and {species_b}.\")\n",
    "\n",
    "        # Filter for one-to-one orthologs\n",
    "        orthologs = self.orthologues_stats.loc[\n",
    "            (self.orthologues_stats[species_a] == 1) & (self.orthologues_stats[species_b] == 1)\n",
    "        ]\n",
    "\n",
    "        return orthologs\n",
    "\n",
    "    def get_hierarchical_orthogroup(self, orthogroup_id):\n",
    "        \"\"\"\n",
    "        Get the genes in a specific hierarchical orthogroup.\n",
    "\n",
    "        Args:\n",
    "            orthogroup_id (str): The ID of the hierarchical orthogroup.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing the genes in the specified orthogroup.\n",
    "        \"\"\"\n",
    "        if self.hierarchical_orthogroups is None:\n",
    "            raise ValueError(\"Hierarchical orthogroups file not loaded.\")\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Retrieving hierarchical orthogroup: {orthogroup_id}\")\n",
    "\n",
    "        # Filter for the specified orthogroup\n",
    "        orthogroup = self.hierarchical_orthogroups[\n",
    "            self.hierarchical_orthogroups[\"HOG\"] == orthogroup_id\n",
    "        ]\n",
    "\n",
    "        return orthogroup\n",
    "\n",
    "    def list_species(self):\n",
    "        \"\"\"\n",
    "        List all species in the OrthoFinder results.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of species names.\n",
    "        \"\"\"\n",
    "        if self.orthologues_stats is None:\n",
    "            raise ValueError(\"One-to-one orthologs statistics file not loaded.\")\n",
    "\n",
    "        return list(self.orthologues_stats.columns)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Provide a pretty string representation of the OrthoFinderResults object.\n",
    "        \"\"\"\n",
    "        repr_str = \"OrthoFinderResults Summary\\n\"\n",
    "        repr_str += f\"Results Directory: {self.results_dir}\\n\"\n",
    "        repr_str += \"-\" * 40 + \"\\n\"\n",
    "\n",
    "        if self.orthologues_stats is not None:\n",
    "            repr_str += f\"One-to-One Orthologs Loaded: {self.orthologues_stats.shape[0]} genes x {self.orthologues_stats.shape[1]} species\\n\"\n",
    "        else:\n",
    "            repr_str += \"One-to-One Orthologs: Not Loaded\\n\"\n",
    "\n",
    "        if self.hierarchical_orthogroups is not None:\n",
    "            repr_str += f\"Hierarchical Orthogroups Loaded: {self.hierarchical_orthogroups.shape[0]} orthogroups\\n\"\n",
    "        else:\n",
    "            repr_str += \"Hierarchical Orthogroups: Not Loaded\\n\"\n",
    "\n",
    "        repr_str += \"-\" * 40 + \"\\n\"\n",
    "        repr_str += \"Available Methods:\\n\"\n",
    "        repr_str += \" - list_species(): List all species in the results\\n\"\n",
    "        repr_str += \" - get_one_to_one_orthologs(species_a, species_b): Retrieve one-to-one orthologs between two species\\n\"\n",
    "        repr_str += \" - get_hierarchical_orthogroup(orthogroup_id): Retrieve genes in a specific hierarchical orthogroup\\n\"\n",
    "\n",
    "        return repr_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ae31171-478e-4a34-badf-c57cc33990d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing OrthoFinderResults for directory: ../results/orthofinder/Results_Jan29\n",
      "Loading one-to-one orthologs from: ../results/orthofinder/Results_Jan29/Comparative_Genomics_Statistics/OrthologuesStats_one-to-one.tsv\n",
      "Loading hierarchical orthogroups from: ../results/orthofinder/Results_Jan29/Phylogenetic_Hierarchical_Orthogroups/N0.tsv\n",
      "Species: ['Aalbopictus_AalbF5-proteins', 'AgambiaePEST-proteins', 'CquinquefasciatusJHB2020-proteins']\n",
      "Retrieving one-to-one orthologs between AgambiaePEST-proteins and Aalbopictus_AalbF5-proteins.\n",
      "Empty DataFrame\n",
      "Columns: [Aalbopictus_AalbF5-proteins, AgambiaePEST-proteins, CquinquefasciatusJHB2020-proteins]\n",
      "Index: []\n",
      "Retrieving hierarchical orthogroup: N0.HOG0000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOG</th>\n",
       "      <th>OG</th>\n",
       "      <th>Gene Tree Parent Clade</th>\n",
       "      <th>Aalbopictus_AalbF5-proteins</th>\n",
       "      <th>AgambiaePEST-proteins</th>\n",
       "      <th>CquinquefasciatusJHB2020-proteins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N0.HOG0000000</td>\n",
       "      <td>OG0000000</td>\n",
       "      <td>n0</td>\n",
       "      <td>XM_019670992.3, XM_029858824.2, XM_019694447.3...</td>\n",
       "      <td>AGAP012560-RA</td>\n",
       "      <td>CQUJHB004840.R7478, CQUJHB009344.R14386, CQUJH...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             HOG         OG Gene Tree Parent Clade  \\\n",
       "0  N0.HOG0000000  OG0000000                     n0   \n",
       "\n",
       "                         Aalbopictus_AalbF5-proteins AgambiaePEST-proteins  \\\n",
       "0  XM_019670992.3, XM_029858824.2, XM_019694447.3...         AGAP012560-RA   \n",
       "\n",
       "                   CquinquefasciatusJHB2020-proteins  \n",
       "0  CQUJHB004840.R7478, CQUJHB009344.R14386, CQUJH...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the OrthoFinderResults class\n",
    "results_dir = \"../results/orthofinder/Results_Jan29\"\n",
    "irtho = OrthoFinderResults(results_dir, debug=True)\n",
    "\n",
    "# List all species\n",
    "species = irtho.list_species()\n",
    "print(\"Species:\", species)\n",
    "\n",
    "# Get one-to-one orthologs between two species\n",
    "orthologs = irtho.get_one_to_one_orthologs(\"AgambiaePEST-proteins\", \"Aalbopictus_AalbF5-proteins\")\n",
    "print(orthologs)\n",
    "\n",
    "# Get a specific hierarchical orthogroup\n",
    "hog = irtho.get_hierarchical_orthogroup(\"N0.HOG0000000\")\n",
    "hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe38dd-b2ad-4090-a335-d633e67547d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6bcad2-8e88-4694-b3ae-049d1f03e8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
